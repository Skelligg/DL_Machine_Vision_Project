{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": "# 4. CNN Built from Scratch\n\n**Student:** Souhaib Othmani\n\n## Purpose\n- Design simple CNN architecture from scratch\n- Implement custom CNN model (similar to course examples)\n- Train for equal number of epochs as pretrained models\n- Compare performance with transfer learning approaches\n- Analyze trade-offs between custom and pretrained models\n\n## Architecture Overview\n\nOur custom CNN follows a classic convolutional neural network design:\n- **Input**: 224x224x3 RGB images (resized from 28x28 grayscale)\n- **Feature Extraction**: 4 convolutional blocks with increasing filters (32 → 64 → 128 → 256)\n- **Classification**: Fully connected layers with dropout for regularization\n- **Output**: 10 classes (Fashion-MNIST categories)"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": "# Import libraries and load setup from previous notebooks\n%run ./01_eda_preprocessing.ipynb\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nfrom torch.utils.tensorboard import SummaryWriter\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\nimport seaborn as sns\nimport os\nfrom tqdm import tqdm\n\n# Set device\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Constants - SAME as baseline for fair comparison\nNUM_CLASSES = 10\nNUM_EPOCHS = 10  # Same as pretrained baseline\nBATCH_SIZE = 64  # Same as baseline\nLEARNING_RATE = 0.001  # Same as baseline\n\nprint(f\"Training configuration:\")\nprint(f\"  - Epochs: {NUM_EPOCHS}\")\nprint(f\"  - Batch size: {BATCH_SIZE}\")\nprint(f\"  - Learning rate: {LEARNING_RATE}\")",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": "## CNN Architecture Design\n\n**Architecture Rationale:**\n\n1. **Convolutional Layers**: We use 4 convolutional blocks with increasing filter counts (32 → 64 → 128 → 256). This progressive increase allows the network to learn increasingly complex features:\n   - Early layers: detect edges, textures, simple patterns\n   - Later layers: detect higher-level features like shapes and object parts\n\n2. **Batch Normalization**: Added after each convolution to stabilize training and allow higher learning rates.\n\n3. **MaxPooling**: 2x2 pooling after each conv block reduces spatial dimensions by half, creating translation invariance and reducing computation.\n\n4. **Dropout**: Applied in fully connected layers (p=0.5) to prevent overfitting.\n\n5. **Kernel Size**: 3x3 kernels throughout - the standard choice balancing receptive field size and parameter count.\n\n**Input → Output Flow:**\n- Input: 224×224×3\n- After Conv Block 1: 112×112×32\n- After Conv Block 2: 56×56×64\n- After Conv Block 3: 28×28×128\n- After Conv Block 4: 14×14×256\n- After Global Avg Pool: 1×1×256\n- Output: 10 classes",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": "# Implement CNN class using nn.Module\n\nclass FashionCNN(nn.Module):\n    \"\"\"\n    Custom CNN architecture for Fashion-MNIST classification.\n    \n    Architecture:\n    - 4 Convolutional blocks with BatchNorm, ReLU, and MaxPool\n    - Global Average Pooling\n    - Fully connected classifier with Dropout\n    \"\"\"\n    \n    def __init__(self, num_classes=10):\n        super(FashionCNN, self).__init__()\n        \n        # Convolutional Block 1: 3 -> 32 channels\n        self.conv1 = nn.Sequential(\n            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(32),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2)  # 224 -> 112\n        )\n        \n        # Convolutional Block 2: 32 -> 64 channels\n        self.conv2 = nn.Sequential(\n            nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(64),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2)  # 112 -> 56\n        )\n        \n        # Convolutional Block 3: 64 -> 128 channels\n        self.conv3 = nn.Sequential(\n            nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(128),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2)  # 56 -> 28\n        )\n        \n        # Convolutional Block 4: 128 -> 256 channels\n        self.conv4 = nn.Sequential(\n            nn.Conv2d(128, 256, kernel_size=3, stride=1, padding=1),\n            nn.BatchNorm2d(256),\n            nn.ReLU(inplace=True),\n            nn.MaxPool2d(kernel_size=2, stride=2)  # 28 -> 14\n        )\n        \n        # Global Average Pooling\n        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1))\n        \n        # Fully Connected Classifier\n        self.classifier = nn.Sequential(\n            nn.Flatten(),\n            nn.Linear(256, 128),\n            nn.ReLU(inplace=True),\n            nn.Dropout(p=0.5),\n            nn.Linear(128, num_classes)\n        )\n        \n        # Weight initialization\n        self._initialize_weights()\n    \n    def _initialize_weights(self):\n        \"\"\"Initialize weights using Kaiming (He) initialization for ReLU activations.\"\"\"\n        for m in self.modules():\n            if isinstance(m, nn.Conv2d):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n                if m.bias is not None:\n                    nn.init.zeros_(m.bias)\n            elif isinstance(m, nn.BatchNorm2d):\n                nn.init.ones_(m.weight)\n                nn.init.zeros_(m.bias)\n            elif isinstance(m, nn.Linear):\n                nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')\n                nn.init.zeros_(m.bias)\n    \n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.conv3(x)\n        x = self.conv4(x)\n        x = self.global_avg_pool(x)\n        x = self.classifier(x)\n        return x\n\n\n# Create model instance\nmodel_scratch = FashionCNN(num_classes=NUM_CLASSES).to(device)\n\n# Print model architecture\nprint(\"FashionCNN Architecture:\")\nprint(\"=\" * 60)\nprint(model_scratch)\nprint(\"=\" * 60)\n\n# Count parameters\ntotal_params = sum(p.numel() for p in model_scratch.parameters())\ntrainable_params = sum(p.numel() for p in model_scratch.parameters() if p.requires_grad)\nprint(f\"\\nTotal parameters: {total_params:,}\")\nprint(f\"Trainable parameters: {trainable_params:,}\")",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": "# Set up training for scratch CNN\n# Using SAME optimizer, learning rate, and batch size as baseline\n\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model_scratch.parameters(), lr=LEARNING_RATE)\n\nprint(\"Training Setup:\")\nprint(f\"  - Optimizer: Adam\")\nprint(f\"  - Learning Rate: {LEARNING_RATE}\")\nprint(f\"  - Loss Function: CrossEntropyLoss\")\nprint(f\"  - Batch Size: {BATCH_SIZE}\")\nprint(f\"  - Epochs: {NUM_EPOCHS}\")",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": "# Initialize TensorBoard logger for scratch CNN\n\nlog_dir = \"runs/cnn_scratch\"\nos.makedirs(log_dir, exist_ok=True)\nwriter = SummaryWriter(log_dir=log_dir)\n\n# Log hyperparameters\nwriter.add_text(\"Hyperparameters\", f\"lr={LEARNING_RATE}, batch_size={BATCH_SIZE}, epochs={NUM_EPOCHS}\")\nwriter.add_text(\"Architecture\", str(model_scratch))\n\nprint(f\"TensorBoard logging initialized at: {log_dir}\")",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": "# Train scratch CNN model\n# Using identical training loop to pretrained model for fair comparison\n\ndef train_one_epoch(model, loader, criterion, optimizer, device):\n    \"\"\"Train model for one epoch.\"\"\"\n    model.train()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    \n    for images, labels in tqdm(loader, desc=\"Training\", leave=False):\n        images, labels = images.to(device), labels.to(device)\n        \n        optimizer.zero_grad()\n        outputs = model(images)\n        loss = criterion(outputs, labels)\n        loss.backward()\n        optimizer.step()\n        \n        running_loss += loss.item() * images.size(0)\n        _, preds = torch.max(outputs, 1)\n        correct += (preds == labels).sum().item()\n        total += labels.size(0)\n    \n    return running_loss / total, correct / total\n\n\ndef validate(model, loader, criterion, device):\n    \"\"\"Validate model on validation set.\"\"\"\n    model.eval()\n    running_loss = 0.0\n    correct = 0\n    total = 0\n    \n    with torch.no_grad():\n        for images, labels in tqdm(loader, desc=\"Validation\", leave=False):\n            images, labels = images.to(device), labels.to(device)\n            outputs = model(images)\n            loss = criterion(outputs, labels)\n            \n            running_loss += loss.item() * images.size(0)\n            _, preds = torch.max(outputs, 1)\n            correct += (preds == labels).sum().item()\n            total += labels.size(0)\n    \n    return running_loss / total, correct / total\n\n\n# Training history\ntrain_losses, val_losses = [], []\ntrain_accs, val_accs = [], []\n\n# Save directory\nsave_dir = \"./saved_models/cnn_scratch\"\nos.makedirs(save_dir, exist_ok=True)\n\nprint(\"=\" * 60)\nprint(\"TRAINING CNN FROM SCRATCH\")\nprint(\"=\" * 60)\n\nfor epoch in range(NUM_EPOCHS):\n    print(f\"\\nEpoch {epoch + 1}/{NUM_EPOCHS}\")\n    \n    train_loss, train_acc = train_one_epoch(model_scratch, train_loader, criterion, optimizer, device)\n    val_loss, val_acc = validate(model_scratch, val_loader, criterion, device)\n    \n    train_losses.append(train_loss)\n    val_losses.append(val_loss)\n    train_accs.append(train_acc)\n    val_accs.append(val_acc)\n    \n    # Log to TensorBoard\n    writer.add_scalars(\"Loss\", {\"train\": train_loss, \"val\": val_loss}, epoch)\n    writer.add_scalars(\"Accuracy\", {\"train\": train_acc, \"val\": val_acc}, epoch)\n    \n    # Save checkpoint\n    checkpoint_path = os.path.join(save_dir, f\"model_epoch_{epoch + 1}.pt\")\n    torch.save(model_scratch.state_dict(), checkpoint_path)\n    \n    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"Training completed!\")\nprint(\"=\" * 60)",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": "# Evaluate scratch CNN on test set\n\nmodel_scratch.eval()\nall_preds, all_labels = [], []\n\nwith torch.no_grad():\n    for images, labels in tqdm(test_loader, desc=\"Testing\"):\n        images, labels = images.to(device), labels.to(device)\n        outputs = model_scratch(images)\n        _, preds = torch.max(outputs, 1)\n        all_preds.extend(preds.cpu().numpy())\n        all_labels.extend(labels.cpu().numpy())\n\n# Compute metrics\naccuracy = accuracy_score(all_labels, all_preds)\nprecision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=\"weighted\")\ncm = confusion_matrix(all_labels, all_preds)\n\nprint(\"=\" * 60)\nprint(\"TEST SET EVALUATION - CNN FROM SCRATCH\")\nprint(\"=\" * 60)\nprint(f\"Test Accuracy: {accuracy:.4f}\")\nprint(f\"Precision: {precision:.4f}\")\nprint(f\"Recall: {recall:.4f}\")\nprint(f\"F1-Score: {f1:.4f}\")\n\n# Display confusion matrix\nprint(\"\\nConfusion Matrix:\")\nprint(cm)\n\n# Plot confusion matrix\nplt.figure(figsize=(10, 8))\nclass_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n            xticklabels=class_names, yticklabels=class_names)\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.title('Confusion Matrix - CNN from Scratch')\nplt.xticks(rotation=45, ha='right')\nplt.tight_layout()\nplt.savefig('./saved_models/cnn_scratch/confusion_matrix.png', dpi=150, bbox_inches='tight')\nplt.show()",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": "# Plot training curves for scratch CNN\n\nepochs_range = range(1, NUM_EPOCHS + 1)\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 5))\n\n# Loss curves\nax1 = axes[0]\nax1.plot(epochs_range, train_losses, 'b-o', label='Training Loss', markersize=6)\nax1.plot(epochs_range, val_losses, 'r-o', label='Validation Loss', markersize=6)\nax1.set_xlabel('Epoch')\nax1.set_ylabel('Loss')\nax1.set_title('CNN from Scratch - Loss Curves')\nax1.legend()\nax1.grid(True, alpha=0.3)\n\n# Accuracy curves\nax2 = axes[1]\nax2.plot(epochs_range, train_accs, 'b-o', label='Training Accuracy', markersize=6)\nax2.plot(epochs_range, val_accs, 'r-o', label='Validation Accuracy', markersize=6)\nax2.set_xlabel('Epoch')\nax2.set_ylabel('Accuracy')\nax2.set_title('CNN from Scratch - Accuracy Curves')\nax2.legend()\nax2.grid(True, alpha=0.3)\n\nplt.tight_layout()\nplt.savefig('./saved_models/cnn_scratch/training_curves.png', dpi=150, bbox_inches='tight')\nplt.show()\n\n# Print final training stats\nprint(\"\\n\" + \"=\" * 60)\nprint(\"FINAL TRAINING STATISTICS\")\nprint(\"=\" * 60)\nprint(f\"Final Training Loss: {train_losses[-1]:.4f}\")\nprint(f\"Final Training Accuracy: {train_accs[-1]:.4f}\")\nprint(f\"Final Validation Loss: {val_losses[-1]:.4f}\")\nprint(f\"Final Validation Accuracy: {val_accs[-1]:.4f}\")\nprint(f\"Best Validation Accuracy: {max(val_accs):.4f} (Epoch {val_accs.index(max(val_accs)) + 1})\")",
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "execution_count": null,
   "metadata": {},
   "source": "## Scratch CNN Analysis\n\nThe custom CNN trained from scratch demonstrates the challenges of learning visual representations without pretrained weights. Compared to the transfer learning approach using ResNet-18 (which achieved ~85.5% test accuracy), the scratch CNN faces several inherent disadvantages:\n\n**Performance Gap:** The scratch CNN is expected to achieve lower accuracy than the pretrained model, particularly within the same 10-epoch training budget. This is because the pretrained ResNet-18 leverages features learned from millions of ImageNet images, providing a powerful starting point. Our scratch CNN must learn all feature representations from scratch using only the Fashion-MNIST training data.\n\n**Convergence Behavior:** The training curves for the scratch CNN typically show a more gradual improvement compared to transfer learning. Early epochs focus on learning basic features (edges, textures), while later epochs refine higher-level representations. The gap between training and validation accuracy indicates the model's generalization capability - a larger gap suggests potential overfitting.\n\n**Architecture Trade-offs:** Our 4-layer CNN is significantly simpler than ResNet-18 (which has 18 layers with skip connections). While this makes our model faster to train and has fewer parameters, it also limits its representational capacity. The absence of residual connections may also make optimization more challenging for deeper configurations.\n\n**Key Observations:**\n1. The scratch CNN requires more epochs to converge to comparable performance\n2. Batch normalization and dropout help stabilize training and reduce overfitting\n3. Similar confusion patterns emerge (shirt/coat/pullover confusion) since these are inherently difficult classes\n4. Transfer learning provides a substantial head start, especially with limited training data or epochs",
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "source": "# Save scratch CNN checkpoint\n\nfinal_checkpoint = os.path.join(save_dir, \"model_checkpoint.pt\")\ntorch.save({\n    'model_state_dict': model_scratch.state_dict(),\n    'optimizer_state_dict': optimizer.state_dict(),\n    'epoch': NUM_EPOCHS,\n    'train_losses': train_losses,\n    'val_losses': val_losses,\n    'train_accs': train_accs,\n    'val_accs': val_accs,\n    'test_accuracy': accuracy,\n    'test_f1': f1,\n    'architecture': 'FashionCNN'\n}, final_checkpoint)\n\n# Close TensorBoard writer\nwriter.close()\n\nprint(\"=\" * 60)\nprint(\"SAVED MODEL CHECKPOINT\")\nprint(\"=\" * 60)\nprint(f\"Checkpoint saved to: {final_checkpoint}\")\nprint(f\"\\nCheckpoint contains:\")\nprint(f\"  - Model weights\")\nprint(f\"  - Optimizer state\")\nprint(f\"  - Training history\")\nprint(f\"  - Test metrics\")\n\n# List all saved files\nprint(f\"\\nAll files in {save_dir}/:\")\nfor f in os.listdir(save_dir):\n    print(f\"  - {f}\")\n\nprint(\"\\n\" + \"=\" * 60)\nprint(\"CNN from Scratch notebook completed successfully!\")\nprint(\"=\" * 60)",
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}