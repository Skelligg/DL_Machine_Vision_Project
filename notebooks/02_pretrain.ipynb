{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# 2. Baseline Pretrained Model Training\n",
    "\n",
    "**Student:** Student 1\n",
    "\n",
    "## Purpose\n",
    "- Load pretrained vision model (ResNet, EfficientNet, VGG, etc.)\n",
    "- Implement transfer learning strategy\n",
    "- Train baseline model with default hyperparameters\n",
    "- Log metrics to TensorBoard\n",
    "- Save model checkpoint\n",
    "- Analyze baseline performance"
   ],
   "id": "4039047d7be6b547"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "%run ./01_data_exploration_preprocessing.ipynb",
   "id": "f90412ceb65f6571"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# TODO: Import libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import models, transforms\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import accuracy_score, precision_recall_fscore_support, confusion_matrix\n",
    "import os\n",
    "from tqdm import tqdm"
   ],
   "id": "22b6c8257934d28a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# TODO: Load DataLoaders from notebook 01\n",
    "# Assuming you saved DataLoaders or can import them\n",
    "# Example: from data_exploration_preprocessing import train_loader, val_loader, test_loader\n",
    "# If not, recreate datasets and loaders with the same preprocessing pipeline\n",
    "\n",
    "\n",
    "num_classes = 10  # Fashion-MNIST has 10 classes\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device:\", device)\n"
   ],
   "id": "9f5a676fd5702edb"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# TODO: Load pretrained model\n",
    "resnet18 = models.resnet18(weights=models.ResNet18_Weights.IMAGENET1K_V1)\n",
    "resnet18 = resnet18.to(device)\n",
    "print(resnet18)\n"
   ],
   "id": "4f86f086045d5b63"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# TODO: Implement transfer learning strategy\n",
    "\n",
    "# Strategy:\n",
    "# Freeze all convolutional layers (feature extractor)\n",
    "for param in resnet18.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Replace final fully connected layer\n",
    "resnet18.fc = nn.Linear(resnet18.fc.in_features, num_classes)\n",
    "resnet18.fc.requires_grad = True  # only this layer is trainable\n",
    "\n",
    "# Move model to device\n",
    "resnet18 = resnet18.to(device)\n",
    "\n",
    "print(\"Transfer learning strategy applied: frozen conv layers, fine-tune FC layer\")\n"
   ],
   "id": "87526b2bf59a994c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# TODO: Set up baseline hyperparameters\n",
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "num_epochs = 10  # choose a value in 5-15 as recommended\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(resnet18.fc.parameters(), lr=learning_rate)\n",
    "\n",
    "print(f\"Hyperparameters: lr={learning_rate}, batch_size={batch_size}, epochs={num_epochs}\")\n"
   ],
   "id": "46dfb75c8edb80a6"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# TODO: Initialize TensorBoard logger\n",
    "log_dir = \"runs/baseline_resnet18\"\n",
    "os.makedirs(log_dir, exist_ok=True)\n",
    "writer = SummaryWriter(log_dir=log_dir)\n",
    "\n",
    "# Log hyperparameters\n",
    "writer.add_text(\"Hyperparameters\", f\"lr={learning_rate}, batch_size={batch_size}, epochs={num_epochs}\")\n"
   ],
   "id": "759858bfc5a8a28c"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# TODO: Implement training loop\n",
    "\n",
    "def train_one_epoch(model, loader, criterion, optimizer, device):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    for images, labels in tqdm(loader, desc=\"Training\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n"
   ],
   "id": "7a9b8dbe409fb7b4"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# TODO: Implement validation loop\n",
    "\n",
    "def validate(model, loader, criterion, device):\n",
    "    model.eval()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for images, labels in tqdm(loader, desc=\"Validation\"):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "\n",
    "            running_loss += loss.item() * images.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / total\n",
    "    epoch_acc = correct / total\n",
    "    return epoch_loss, epoch_acc\n"
   ],
   "id": "5d2022c9df0d220a"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# TODO: Train baseline model\n",
    "\n",
    "train_losses, val_losses = [], []\n",
    "train_accs, val_accs = [], []\n",
    "\n",
    "save_dir = \"saved_models/baseline_pretrained\"\n",
    "os.makedirs(save_dir, exist_ok=True)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "\n",
    "    train_loss, train_acc = train_one_epoch(resnet18, train_loader, criterion, optimizer, device)\n",
    "    val_loss, val_acc = validate(resnet18, val_loader, criterion, device)\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    val_losses.append(val_loss)\n",
    "    train_accs.append(train_acc)\n",
    "    val_accs.append(val_acc)\n",
    "\n",
    "    # Log to TensorBoard\n",
    "    writer.add_scalars(\"Loss\", {\"train\": train_loss, \"val\": val_loss}, epoch)\n",
    "    writer.add_scalars(\"Accuracy\", {\"train\": train_acc, \"val\": val_acc}, epoch)\n",
    "\n",
    "    # Save checkpoint\n",
    "    checkpoint_path = os.path.join(save_dir, f\"model_epoch_{epoch + 1}.pt\")\n",
    "    torch.save(resnet18.state_dict(), checkpoint_path)\n",
    "\n",
    "    print(f\"Train Loss: {train_loss:.4f}, Train Acc: {train_acc:.4f}\")\n",
    "    print(f\"Val Loss: {val_loss:.4f}, Val Acc: {val_acc:.4f}\")\n"
   ],
   "id": "336583d302e4e174"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# TODO: Evaluate baseline on test set\n",
    "resnet18.eval()\n",
    "all_preds, all_labels = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in tqdm(test_loader, desc=\"Testing\"):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = resnet18(images)\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "precision, recall, f1, _ = precision_recall_fscore_support(all_labels, all_preds, average=\"weighted\")\n",
    "cm = confusion_matrix(all_labels, all_preds)\n",
    "\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}, Recall: {recall:.4f}, F1-score: {f1:.4f}\")\n",
    "print(\"Confusion Matrix:\\n\", cm)\n"
   ],
   "id": "3893e52e8cb6652d"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# TODO: Plot training curves\n",
    "epochs = np.arange(1, num_epochs + 1)\n",
    "\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs, train_losses, label=\"Train Loss\")\n",
    "plt.plot(epochs, val_losses, label=\"Validation Loss\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.title(\"Loss curves\")\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs, train_accs, label=\"Train Acc\")\n",
    "plt.plot(epochs, val_accs, label=\"Validation Acc\")\n",
    "plt.xlabel(\"Epoch\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.legend()\n",
    "plt.title(\"Accuracy curves\")\n",
    "\n",
    "plt.show()\n"
   ],
   "id": "67e50d1140c6ff06"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# TODO: Write baseline performance analysis (example)\n",
    "\"\"\"\n",
    "The ResNet18 baseline achieves good accuracy on Fashion-MNIST after fine-tuning only the final layer.\n",
    "Training and validation loss curves indicate the model converges quickly without significant overfitting.\n",
    "The confusion matrix shows that the model performs slightly worse on visually similar classes (e.g., shirts vs. tops),\n",
    "but overall classification is strong for most categories.\n",
    "\n",
    "Since only the final fully connected layer was fine-tuned, the feature extractor from ImageNet transfers well.\n",
    "Future experiments could include unfreezing some deeper layers or adding mild data augmentation to further improve accuracy.\n",
    "\"\"\"\n"
   ],
   "id": "c6fd39be453d9e88"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# TODO: Save baseline model checkpoint\n",
    "final_checkpoint = os.path.join(save_dir, \"model_checkpoint.pt\")\n",
    "torch.save(resnet18.state_dict(), final_checkpoint)\n",
    "print(f\"Baseline ResNet18 checkpoint saved to {final_checkpoint}\")\n"
   ],
   "id": "44e4d8c0d2dd6497"
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
